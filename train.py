import torch
from torchvision import datasets, transforms
from torch import nn, optim

# ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„°
batch_size = 64
epochs = 5
learning_rate = 0.01

# ğŸ“¦ ë°ì´í„° ë¡œë”© (MNIST)
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

# ğŸ§  ëª¨ë¸ ì •ì˜
class SimpleNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = nn.Sequential(
            nn.Flatten(),
            nn.Linear(28*28, 128),
            nn.ReLU(),
            nn.Linear(128, 10)
        )

    def forward(self, x):
        return self.model(x)

model = SimpleNN()
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=learning_rate)

# ğŸ” í•™ìŠµ ë£¨í”„
for epoch in range(epochs):
    model.train()
    total_loss = 0
    for images, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}")

# ğŸ’¾ ëª¨ë¸ ì €ì¥
torch.save(model.state_dict(), "trained_mnist_model.pth")
print("âœ… í•™ìŠµ ì™„ë£Œ ë° ëª¨ë¸ ì €ì¥ë¨: trained_mnist_model.pth")
